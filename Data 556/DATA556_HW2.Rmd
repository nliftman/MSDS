---
title: "Data 556 HW 2"
author: "Naomi Liftman"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r}
#loading the package that includes rv distributions and ggplot
library(stats)
library(ggplot2)
```
# 2a.Use simulations to numerically estimate mean & variance of A. 
```{r}
#setting a seed so its reproducible
set.seed(99)

nsims=10000
records = rep(0,nsims)

for(i in 1:nsims){
  radius <- runif(1, min = 0, max = 1)
  records[i] <- ((radius^2)*pi)
}

#expectation of the area (the area is the records)
e_a = sum(records)/nsims #1.048
var_a = var(records) #.8768
```

# 3a. Use simulations to gain understadning about the distribution of R. Numerically estimate the expected value of R and 1/R. 
```{r}
#set seed
set.seed(100)

nsims=10000
records_x = rep(0,nsims)
records_y = rep(0,nsims)
records_ratio = rep(0,nsims)
one_r = rep(0,nsims)

for(i in 1:nsims){
  x <- runif(1, min = 0, max = 1)
  y = 1-x
  records_x[i] <- x
  records_y[i] <- y
  records_ratio[i] <- (x/y)
  one_r[i] <- (y/x)
}

e_r = sum(records_ratio)/10000 #9.0554
e_r_one = sum(one_r)/10000 #8.438

```

# 4a. Let $U_1$, .... $U_n$ be iid Unif(0,1) and x=max(iids). Use R to numerically estimate E(x). 
```{r}
set.seed(100)

nsims = 10000
xrecords = rep(0,nsims)

for(i in 1:nsims){
  x <- runif(1, min = 0, max = 1)
  xrecords[i] <- x 
}

e_r = sum(xrecords)/10000 # .50029
```

# 5b. Use R to numerically estimate P(X<Y) for X - N(0,1), Y - N(1,5) w X and Y being independent. 
```{r}
set.seed(100)

nsims = 10000
records_x_y = rep(0,nsims)

for(i in 1:nsims){
  x <- rnorm(1, mean = 0, sd = 1)
  y <- rnorm(1, mean = 1, sd = 5)
  records_x_y[i] <- (x<y)
}

exy = sum(records_x_y)/nsims # .5759

```


# 6b. Use R to calculate the Monte Carlo estimates of mean + SD of x-y.
```{r}
set.seed(100)

nsims=10000
records_x = rep(0,nsims)
records_y = rep(0,nsims)
records_ratio = rep(0, nsims)

for(i in 1:nsims){
  x <- rnorm(1, mean = 69.1, sd = 2.9)
  y <- rnorm(1, mean = 63.7, sd = 2.7)
  records_x[i] <- x
  records_y[i] <- y
  records_ratio[i] <- (x - y)
}

e_r = sum(records_ratio)/10000 # 5.396
sd <- sd(records_ratio) #3.942
```

# 6c. What is the probability that a randomly sampled man is taller than a randomly sampled woman?
```{r}
pnorm(63.7, mean = 5.4, .2, lower.tail = FALSE)
```

# 7b. For y = 0 make a plot for P(theta given y) for each theta within {0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0}. Make a plot with horizontal axis the 11 values of theta and verticle the P(theta given y).

```{r}
#making a df 
theta <- c(0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1)
p_theta <- c(1, .59, .33, .17, .08, .03, .01, .002, 0, 0, 0)

df_theta <- data.frame(theta, p_theta)

ggplot(df_theta, aes(x= theta, y = p_theta)) + geom_point()

```

# 7c. Repeat (b) for each y within {1,2,3,4,5}. 

```{r}
#making a df for 1 and graph
theta_1 <- c(0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1)
p_theta_1 <- c((0^1)*(1^4), (.1^1)*(.9^4), (.2^1)*(.8^4), (.3^1)*(.7^4), (.4^1)*(.6^4), (.5^1)*(.5^4), (.6^1)*(.4^4), (.7^1)*(.3^4), (.8^1)*(.2^4), (.9^1)*(.1^4), (1^1)*(0^4))
df_theta_1 <- data.frame(theta, p_theta)
ggplot(df_theta_1, aes(x= theta_1, y = p_theta_1)) + geom_point()

#df and graph for 2
theta_2 <- c(0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1)
p_theta_2 <- c((0^2)*(1^3), (.1^2)*(.9^3), (.2^2)*(.8^3), (.3^2)*(.7^3), (.4^2)*(.6^3), (.5^2)*(.5^3), (.6^2)*(.4^3), (.7^2)*(.3^3), (.8^2)*(.2^3), (.9^2)*(.1^3), (1^2)*(0^3))
df_theta_2 <- data.frame(theta, p_theta)
ggplot(df_theta_2, aes(x= theta_2, y = p_theta_2)) + geom_point()

#df and graph for 3
theta_2 <- c(0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1)
p_theta_2 <- c((0^3)*(1^2), (.1^3)*(.9^2), (.2^3)*(.8^2), (.3^3)*(.7^2), (.4^3)*(.6^2), (.5^3)*(.5^2), (.6^3)*(.4^2), (.7^3)*(.3^2), (.8^3)*(.2^2), (.9^3)*(.1^2), (1^3)*(0^2))
df_theta_2 <- data.frame(theta, p_theta)
ggplot(df_theta_2, aes(x= theta_2, y = p_theta_2)) + geom_point()

#df and graph for 4
theta_4 <- c(0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1)
p_theta_4 <- c((0^4)*(1^1), (.1^4)*(.9^1), (.2^4)*(.8^1), (.3^4)*(.7^1), (.4^4)*(.6^1), (.5^4)*(.5^1), (.6^4)*(.4^1), (.7^4)*(.3^1), (.8^4)*(.2^1), (.9^4)*(.1^1), (1^4)*(0^1))
df_theta_4 <- data.frame(theta, p_theta)
ggplot(df_theta_4, aes(x= theta_4, y = p_theta_4)) + geom_point()

#df and graph for 5
theta_5 <- c(0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1)
p_theta_5 <- c((0^5)*(1^0), (.1^5)*(.9^0), (.2^5)*(.8^0), (.3^5)*(.7^0), (.4^5)*(.6^0), (.5^5)*(.5^0), (.6^5)*(.4^0), (.7^5)*(.3^0), (.8^5)*(.2^0), (.9^5)*(.1^0), (1^5)*(0^0))
df_theta_5 <- data.frame(theta, p_theta)
ggplot(df_theta_5, aes(x= theta_5, y = p_theta_5)) + geom_point()
```

# 8b. Implement your sampling algoritm in R and use your code to produce a Monte Carlo estimate of P(X lives within (2,3)) where X is a r.v. with a logistic distribution. 

```{r}
#setting a seed so its reproducible
set.seed(99)

nsims=10000
records = rep(0,nsims)
records

for(i in 1:nsims){
  x <- runif(1, min = 0, max = 1)
  xmake_change <- ((1/x) + 1)
  xlogistic <- -log(xmake_change, base = exp(1))
  records[i] <- (2 < xlogistic & xlogistic < 3)
}

# The probability is zero becuase non of ours fall between 2 and three?
```



